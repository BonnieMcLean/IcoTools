lowerNeg <- negCI$bca[[4]]
upperNeg <- negCI$bca[[5]]
# Bootstrap the correlation between each positive rating, and the by-item average
posBoot <- boot(posData, bootCor, R=R)
rPos <- posBoot$t0
posCI <- boot.ci(posBoot, type="bca")
lowerPos <- posCI$bca[[4]]
upperPos <- posCI$bca[[5]]
return(list(list(lowerPos,upperPos,rPos), list(lowerNeg,upperNeg,rNeg)))
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<-% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
R <- 5000
# Bootstrap function, calculating the correlation coefficient for each bootstrapped sample
bootCor <- function(data, i){
d <- data[i,]
rDf <- correlate(d %>% select(-task))
return(rDf[[2,2]])
}
# Split the data by halves of the rating scale, apply the above bootstrap function, and extract confidence intervals
corRatings <- function(data){
# Separate the data into half-scales
negData <- data %>% filter(status=="antiiconic")%>%select(-status)
posData <- data %>% filter(status=="not antiiconic")%>%select(-status)
# Bootstrap the correlation between each negative rating, and the by-item average
negBoot <- boot(negData, bootCor, R=R)
negCI <- boot.ci(negBoot, type="bca")
rNeg <- negBoot$t0
lowerNeg <- negCI$bca[[4]]
upperNeg <- negCI$bca[[5]]
# Bootstrap the correlation between each positive rating, and the by-item average
posBoot <- boot(posData, bootCor, R=R)
rPos <- posBoot$t0
posCI <- boot.ci(posBoot, type="bca")
lowerPos <- posCI$bca[[4]]
upperPos <- posCI$bca[[5]]
return(list(list(lowerPos,upperPos,rPos), list(lowerNeg,upperNeg,rNeg)))
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<-% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %>% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
library(tidyverse)
library(corrr)
library(boot)
library(zeallot)
library(pander)
library(lme4)
library(lmerTest)
theme_set(theme_bw())
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<-% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip()
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +xlim(0.1,0.5)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +expand_limits(x=0)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=0,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip()
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip()
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0.1,0.5)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0.1,1)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0.1,0.6)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0.1,0.6)
datasets <- list(perlman)
R <- 5000
# Bootstrap function, calculating the correlation coefficient for each bootstrapped sample
bootCor <- function(data, i){
d <- data[i,]
rDf <- correlate(d %>% select(-task))
return(rDf[[2,2]])
}
# Split the data by halves of the rating scale, apply the above bootstrap function, and extract confidence intervals
corRatings <- function(data){
# Separate the data into half-scales
# negData <- data %>% filter(status=="antiiconic")%>%select(-status)
# posData <- data %>% filter(status=="not antiiconic")%>%select(-status)
negData <- data %>% filter(rating<0)
posData <- data %>% filter(rating>0)
# Bootstrap the correlation between each negative rating, and the by-item average
negBoot <- boot(negData, bootCor, R=R)
negCI <- boot.ci(negBoot, type="bca")
rNeg <- negBoot$t0
lowerNeg <- negCI$bca[[4]]
upperNeg <- negCI$bca[[5]]
# Bootstrap the correlation between each positive rating, and the by-item average
posBoot <- boot(posData, bootCor, R=R)
rPos <- posBoot$t0
posCI <- boot.ci(posBoot, type="bca")
lowerPos <- posCI$bca[[4]]
upperPos <- posCI$bca[[5]]
return(list(list(lowerPos,upperPos,rPos), list(lowerNeg,upperNeg,rNeg)))
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<-% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'pos', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'neg', negR, negLower, negUpper)
}
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0.1,0.6)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0,0.6)
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0,0.6)
View(guesses_trans)
View(guesses_words)
View(guessing_res)
guessing_res%>%
select(identifier,score)%>%
unique()->guessing_res
length(guessing_res[score<1/3])
guessing_res
which(guessing_res$score<1/3)
length(which(guessing_res$score<1/3))
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
library(tidyverse)
# for guessing between translations
responses_trans <- read.csv('responses-guessingtrans.csv')
control_items <- c("pyoNpyoN","katai","hayai")
responses_trans%>%
filter(word %in% control_items)%>%
select(Prolific.ID,word,answer,time_taken,Task.Description)%>%
group_by(Prolific.ID)%>%
mutate(check_score=sum(answer=='correct')/sum(answer=='incorrect'|answer=='correct'))%>%
select(-word,-answer)%>%
unique()%>%
# also look at whether they were particularly slow or fast to do the experiment
mutate(deviation_timetaken=time_taken-mean(.$time_taken))%>%
mutate(std_deviation=sd(.$time_taken))->examine_participants
# results from the following participants were excluded
exclude_participants<-c('5b3648e7f726b2000192b3f4','5f350486d0c0764216b6745e','5c426de31ddd660001c99cdd')
guesses_trans <- responses_trans%>%
filter(!(Prolific.ID %in% exclude_participants))
# for guessing between words
guesses_words<-read.csv('responses-guessingwords.csv')
control_items <- c("pyoNpyoN","katai","hisohiso")
guesses_words%>%
filter(word %in% control_items)%>%
select(prolific_ID,word,answer,TimeTaken,TaskDesc)%>%
group_by(prolific_ID)%>%
mutate(check_score=sum(answer=='correct')/sum(answer=='incorrect'|answer=='correct'))%>%
select(-word,-answer)%>%
unique()%>%
# also look at whether they were particularly slow or fast to do the experiment
mutate(deviation_timetaken=TimeTaken-mean(.$TimeTaken))%>%
mutate(std_deviation=sd(.$TimeTaken))->examine_participants
# for ratings
ratings <- read_csv("responses-ratings.csv")
ratings%>%
filter(form=="pyoNpyoN"|form=="katai"|form=="hisohiso")%>%
select(experiment,prolificID,form,rating,taskdesc)->examine
# we can exclude raters with low person-total correlation
# calculate mean rating per word
ratings%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))->ratings
participants <- unique(ratings$prolificID)
# get the correlation with the means for each participant
correlations <- c()
for (p in participants){
d <- subset(ratings,prolificID==p)
t <- cor.test(d$rating,d$mean_rating)
coefficient <- t$estimate
correlations <- c(correlations,coefficient)
}
names(correlations) <- participants
# exclude participants with low correlations to the mean
exclude <- names(correlations[which(correlations<=0.2)])
#ratings <- subset(ratings,!(prolificID %in% exclude))
words<-unique(guesses_trans$word_spec)
# see whether the responses differed significantly depending on the answer sentence given
n=0
doubly_tested_words <- c()
weird_words<-c()
for(w in words){
d<-subset(guesses_trans,word_spec==w)
t<-table(d$answer_sen,d$answer)
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
length(unique(weird_words))
# see whether the responses different signficantly depending on the foil sentence given
for(w in words){
d<-subset(guesses_trans,word_spec==w)
t<-table(d$foil_sen,d$answer)
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
guesses_words%>%
mutate(word_spec=paste(word,concept,sep="_"))->guesses_words
words<-unique(guesses_words$word_spec)
# see whether the responses differed significantly depending on the answer sentence given
n=0
doubly_tested_words <- c()
weird_words<-c()
for(w in words){
d<-subset(guesses_words,word_spec==w)
t<-table(d$trans,d$answer)
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
# see whether the responses different signficantly depending on the foil sentence given
for(w in words){
d<-subset(guesses_words,word_spec==w)
t<-table(d$foil,d$answer)
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
#length(unique(doubly_tested_words))
#length(unique(weird_words))
guesses_words <- subset(guesses_words,!(word_spec %in% weird_words))
guesses_words%>%
select(identifier=word_spec,answer)%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))->guessing_res
guesses_words%>%
select(identifier=word_spec,answer)%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
select(identifier,score)%>%
unique()->guessing_res
131-15
length(which(guessing_res$score<1/3))
length(which(guessing_res$score<=1/3))
15/116
12/116
guessing_res%>%
filter(score<1/3)->antiiconic
View(antiiconic)
antiiconic
random <- read_csv("responses-randomfoils.csv")
random <- read_csv("results-randomfoils.csv")
random
random%>%
group_by(identifier)%>%
mutate(score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))
random%>%
group_by(identifier)%>%
mutate(score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))%>%
select(identifier,score)%>%
unique()
random%>%
group_by(identifier)%>%
mutate(score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))%>%
select(identifier,score)%>%
unique()->random
random <- read_csv("results-randomfoils.csv")
random%>%
group_by(identifier)%>%
mutate(random_score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))%>%
select(identifier,score)%>%
unique()->random_res
random%>%
group_by(identifier)%>%
mutate(random_score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))%>%
select(identifier,random_score)%>%
unique()->random_res
t <- left_join(antiiconic,random_res)
t
ratings%>%
select(identifier,rating)%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))->rating_res
View(rating_res)
ratings%>%
select(identifier,rating)%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))%>%
select(identifier,mean_rating)%>%
unique()->rating_res
arousal <- read_csv("arousal_ratings")
arousal <- read_csv("arousal_ratings.csv")
arousal
arousal%>%
select(Word,A.Mean.Sum)
arousal%>%
select(Word,A.Mean.Sum)->arousal_ratings
rating_res
arousal%>%
select(Word,A.Mean.Sum)%>%
rename(identifier=Word)->arousal_ratings
left_join(arousal,rating_res)
arousal
inner_join(arousal_ratings,rating_res)
arousal_ratings
ratings
ratings%>%
select(trans,rating)
ratings%>%
ungroup()%>%
select(trans,rating)->test
test
ratings%>%
ungroup()%>%
select(trans,rating)%>%
mutate(identifier=str_to_lower(trans))->test
test
inner_join(arousal_ratings,rating_res)
arousal_ratings
inner_join(arousal_ratings,test)
t <- inner_join(arousal_ratings,test)
unique(t$identifier)
t
cor.test(t$rating,t$A.Mean.Sum)
plot(t$rating,t$A.Mean.Sum)
cor.test(t$rating,t$A.Mean.Sum)
guessing_words
guessing_res
hist(guessing_res$score)
hist(guessing_res$score,xlim = 0)
hist(guessing_res$score,xlim = c(0,1))
rating_res
hist(rating_res$mean_rating,xlim = c(0,7))
hist(rating_res$mean_rating,xlim = c(0,6))
guessing_res
length(which(guessing_res$score<1/3)
length(which(guessing_res$score<1/3))
length(guessing_res$score[which(guessing_res$score<1/3)])
length(guessing_res$score[which(guessing_res$score>2/3)])
25/116
length(guessing_res$score[which(guessing_res$score>=2/3)])
length(guessing_res$score[which(guessing_res$score<=2/3)])
length(guessing_res$score[which(guessing_res$score<=1/3)])
15/116
31/116
15/116
31/116
shiny::runApp('C:/Users/bonmc643/CookingBlog')
runApp('C:/Users/bonmc643/CookingBlog')
runApp('C:/Users/bonmc643/CookingBlog')
